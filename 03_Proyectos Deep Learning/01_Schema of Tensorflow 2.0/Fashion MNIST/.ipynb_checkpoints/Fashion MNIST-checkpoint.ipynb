{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "711503a8-4ead-474c-9bba-09f2ae115f31",
   "metadata": {},
   "source": [
    "# Importación librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e9af45-3a83-485b-ad8d-8dc25fda2d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95d93c1-50c5-4506-ab56-48ea0cb7a2fd",
   "metadata": {},
   "source": [
    "# Pre procesado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c638156b-4c84-4fde-979c-e95d73ffc9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del dataset\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f618fe6b-dd4a-4b7d-8203-93a14c915ac8",
   "metadata": {},
   "source": [
    "## Normalización de las imagenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19152928-deba-4466-82b4-65e3991a0683",
   "metadata": {},
   "source": [
    "Se divide cada imagen en los conjuntos de entrenamiento y de testing entre el valor máximo de cada uno de los píxeles (255).\n",
    "\n",
    "De este modo, cada píxel se allará en el rango [0, 1]. Al normalizar las imágenes, nos aseguramos que el modelo de RNA entrenará de forma mas eficiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24613f33-6b26-4606-b91e-328f39e79dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de2d7f6-ba3e-495d-b5a8-c16468aff5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e59374-880f-4513-9441-75aaf45a7435",
   "metadata": {},
   "source": [
    "## Redimensionar el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f39de65-bc76-4c49-bd2b-2b8e992685ae",
   "metadata": {},
   "source": [
    "Al tratarse de una red neuronal totalmente conectada, se procede a redimensionar los subconjuntos de entrenamiento y de testing a formato de vector en vez de formato de matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0511b6ee-e637-4ccc-af33-9f6240c29ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como cada imagen tiene 28x28 píxeles, usamos la función reshape en todo el dataset de entrenamiento para convertirlo \n",
    "#en vectores de tamaño [-1 (todos los elementos), anchura * altura]\n",
    "\n",
    "X_train = X_train.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e01540b-703c-49b2-b331-a6b3ee44772f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70fbd368-c8db-4591-8031-35102f16f23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redimensionamos el conjunto de testing del mismo modo\n",
    "\n",
    "X_test = X_test.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b48aac0a-7a4a-4d25-b7ff-eb36b013841e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6cde49-343c-472f-a797-80971c865f90",
   "metadata": {},
   "source": [
    "# Construcción de la Red Neuronal Artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cd4e91-3309-4554-9509-d6e79a5777ba",
   "metadata": {},
   "source": [
    "## Definición del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffebf1a6-993c-4fce-9afb-9d2877a67c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b601f719-cf8a-42ab-8cc9-b7682c00e8f8",
   "metadata": {},
   "source": [
    "## Añadir la primera capa totalmente conectada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05fc2097-c33c-46ef-91be-62408759fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units = 128, activation = 'relu', input_shape = (784, )))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f1e2e2-9af0-4db1-a6f6-07b3fd421fa1",
   "metadata": {},
   "source": [
    "## Añadir una capa de Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884904fd-f089-4272-814e-bec495df2cec",
   "metadata": {},
   "source": [
    "Dropout es una técnica de Regularization donde aleatoriamente se asignan a ciertas neuronas de la red el valor cero. De este modo, mientras se entrena, estas neuronas no actualizarán sus valores. Al tener cierto porcentaje de neuronas sin actualizar, el proceso de entrenamiento toma más tiempo pero por contra tenemos menos posibilidades de sufrir overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75d8561e-57c2-4031-a9ca-7f518de0dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2586186-6284-41f8-b56e-f3fcc8f00a16",
   "metadata": {},
   "source": [
    "## Añadir la capa de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79d34e8-19d9-4701-9d18-50a10cfd49ef",
   "metadata": {},
   "source": [
    "- Unidades: número de clases (10 en el caso del Fashion MNIST)\n",
    "- Función de activación: 'softmax' (probabilidades de cada clase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeb36ef4-ec9c-4200-af93-cc8571be13b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec327446-1e91-459d-af01-79b4f4a81bc3",
   "metadata": {},
   "source": [
    "## Compilar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7884724c-d9ed-4970-9b74-1e689b897778",
   "metadata": {},
   "source": [
    "- Optimizer: Adam\n",
    "- Loss: Sparse softmax (categorical) crossentropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfd78fac-7856-4edc-83fa-d05c17bde7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89413a8d-b046-453a-9c71-2b457e314236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7cb5f5-fc7f-428a-af6b-a223e1caa3d6",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d56122c-75bb-4fb8-9763-9c88d72a0a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 2s 836us/step - loss: 0.3187 - sparse_categorical_accuracy: 0.8825\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 2s 861us/step - loss: 0.3071 - sparse_categorical_accuracy: 0.8855\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 2s 897us/step - loss: 0.3028 - sparse_categorical_accuracy: 0.8877\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 2s 831us/step - loss: 0.2942 - sparse_categorical_accuracy: 0.8908\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 2s 819us/step - loss: 0.2876 - sparse_categorical_accuracy: 0.8915\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 2s 831us/step - loss: 0.2805 - sparse_categorical_accuracy: 0.8964\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 2s 877us/step - loss: 0.2745 - sparse_categorical_accuracy: 0.8977\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 2s 843us/step - loss: 0.2672 - sparse_categorical_accuracy: 0.8998\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 2s 823us/step - loss: 0.2642 - sparse_categorical_accuracy: 0.9007\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 2s 832us/step - loss: 0.2586 - sparse_categorical_accuracy: 0.9024\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 2s 832us/step - loss: 0.2528 - sparse_categorical_accuracy: 0.9047\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 2s 835us/step - loss: 0.2503 - sparse_categorical_accuracy: 0.9056\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 2s 920us/step - loss: 0.2439 - sparse_categorical_accuracy: 0.9089\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 2s 837us/step - loss: 0.2416 - sparse_categorical_accuracy: 0.9087\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 2s 820us/step - loss: 0.2397 - sparse_categorical_accuracy: 0.9084\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 2s 830us/step - loss: 0.2371 - sparse_categorical_accuracy: 0.9102\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 2s 834us/step - loss: 0.2314 - sparse_categorical_accuracy: 0.9118\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 2s 828us/step - loss: 0.2316 - sparse_categorical_accuracy: 0.9136\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 2s 829us/step - loss: 0.2261 - sparse_categorical_accuracy: 0.9145\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 2s 837us/step - loss: 0.2228 - sparse_categorical_accuracy: 0.9161\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 2s 878us/step - loss: 0.2198 - sparse_categorical_accuracy: 0.9163 0s - loss: 0.2189 - sparse_categorical_acc\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 2s 893us/step - loss: 0.2168 - sparse_categorical_accuracy: 0.9176 0s - loss: 0.2174 - sparse_categorical_ac\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 2s 921us/step - loss: 0.2117 - sparse_categorical_accuracy: 0.9191\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 2s 845us/step - loss: 0.2132 - sparse_categorical_accuracy: 0.9188\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 2s 857us/step - loss: 0.2099 - sparse_categorical_accuracy: 0.9204\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 2s 880us/step - loss: 0.2082 - sparse_categorical_accuracy: 0.9203\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 2s 848us/step - loss: 0.2052 - sparse_categorical_accuracy: 0.9213\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 2s 841us/step - loss: 0.2013 - sparse_categorical_accuracy: 0.9229\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 2s 831us/step - loss: 0.2017 - sparse_categorical_accuracy: 0.9230\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 2s 860us/step - loss: 0.2014 - sparse_categorical_accuracy: 0.9235\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 2s 866us/step - loss: 0.2000 - sparse_categorical_accuracy: 0.9251\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 2s 868us/step - loss: 0.1957 - sparse_categorical_accuracy: 0.9257\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 2s 904us/step - loss: 0.1923 - sparse_categorical_accuracy: 0.9264\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 2s 838us/step - loss: 0.1909 - sparse_categorical_accuracy: 0.9271\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 2s 851us/step - loss: 0.1868 - sparse_categorical_accuracy: 0.9283 1s - loss: 0.1942 - sparse_ca\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 2s 876us/step - loss: 0.1881 - sparse_categorical_accuracy: 0.9276\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 2s 859us/step - loss: 0.1839 - sparse_categorical_accuracy: 0.9293\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 2s 846us/step - loss: 0.1856 - sparse_categorical_accuracy: 0.9293\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 2s 846us/step - loss: 0.1838 - sparse_categorical_accuracy: 0.9304\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 2s 826us/step - loss: 0.1811 - sparse_categorical_accuracy: 0.9313\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 2s 843us/step - loss: 0.1813 - sparse_categorical_accuracy: 0.9307\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 2s 872us/step - loss: 0.1747 - sparse_categorical_accuracy: 0.9334\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 2s 895us/step - loss: 0.1768 - sparse_categorical_accuracy: 0.9324\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 2s 836us/step - loss: 0.1750 - sparse_categorical_accuracy: 0.9327 1s - loss: 0.1690 - sparse_categori\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 2s 851us/step - loss: 0.1755 - sparse_categorical_accuracy: 0.9328\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 2s 847us/step - loss: 0.1720 - sparse_categorical_accuracy: 0.9344\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 2s 826us/step - loss: 0.1734 - sparse_categorical_accuracy: 0.9328\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 2s 840us/step - loss: 0.1700 - sparse_categorical_accuracy: 0.9350\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 2s 844us/step - loss: 0.1667 - sparse_categorical_accuracy: 0.9360\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 2s 830us/step - loss: 0.1682 - sparse_categorical_accuracy: 0.9356 0s - loss: 0.1680 - sparse_categorical_accuracy: 0.936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13ef9d253a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d84570c-7048-45eb-8b3e-4f70fa53e152",
   "metadata": {},
   "source": [
    "## Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "367c36f9-5bbc-4f81-99ca-1b3660ef7750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 554us/step - loss: 0.3975 - sparse_categorical_accuracy: 0.8898\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9cce59b-fce6-4021-87dd-a786cf2222c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy: 0.8898000121116638\n"
     ]
    }
   ],
   "source": [
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a958a1f1-30b4-4f69-bd52-394093032113",
   "metadata": {},
   "source": [
    "## Guardar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64da30a5-057f-44b3-b335-7affeb4eab6b",
   "metadata": {},
   "source": [
    "### Gauradar la arquitectura (topología) de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6985d65f-473b-4d46-9da7-177885d5f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"fashion_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db01f2a-9cfb-4e02-87c5-32a50f801d8d",
   "metadata": {},
   "source": [
    "### Gaurdar los pesos de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed6f754a-cc72-4295-aac8-e4d9feec456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"fashion_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb10bac-7a8e-4d06-8704-2cae235faf40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
